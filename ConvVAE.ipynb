{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     23,
     75,
     79
    ],
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-05-29T15:00:18.352Z",
     "iopub.status.busy": "2020-05-29T15:00:18.348Z",
     "iopub.status.idle": "2020-05-29T15:00:27.054Z",
     "shell.execute_reply": "2020-05-29T15:00:27.067Z"
    },
    "id": "49tlzgV-CIIi",
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"residual_conv_vae_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "residual_conv_regressor_2 (R multiple                  116714    \n",
      "_________________________________________________________________\n",
      "sequential_8 (Sequential)    multiple                  262272    \n",
      "_________________________________________________________________\n",
      "residual_conv_regressor_3 (R multiple                  108251    \n",
      "=================================================================\n",
      "Total params: 487,237\n",
      "Trainable params: 485,669\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n",
      "(4, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "#Declare class\n",
    "\n",
    "from tensorflow.keras import layers as L \n",
    "import tensorflow as tf\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class ResidualConv(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size, use_bn=True, activation=tf.nn.elu, **kwargs):\n",
    "        super().__init__()\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.c1 = tf.keras.layers.Conv2D(filters, kernel_size, padding='SAME', **kwargs)\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.c2 = tf.keras.layers.Conv2D(filters, kernel_size, padding='SAME', **kwargs)\n",
    "        self.activation = activation\n",
    "    \n",
    "    def call(self, x):\n",
    "        y = self.activation(self.c1(self.bn1(x)))\n",
    "        y = self.activation(self.c2(self.bn2(y)))\n",
    "        #print(x.shape)\n",
    "        return y + x\n",
    "\n",
    "def round_even(x):\n",
    "    if x % 2 == 0:\n",
    "        return x + 1\n",
    "    else:\n",
    "        return x + 2\n",
    "    \n",
    "class ConvRegressor(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, filters, kernel_size, \n",
    "        conv_type=tf.keras.layers.Conv2D, activation=tf.nn.elu, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.conv_type = conv_type\n",
    "        self.convs = []\n",
    "        for n_filter in filters:\n",
    "            self.convs.append(\n",
    "                conv_type(n_filter, round_even(kernel_size), strides=2, padding='SAME', activation=activation, **kwargs)\n",
    "            )\n",
    "            self.convs.append(conv_type(n_filter, kernel_size, padding='SAME', activation=activation, **kwargs))\n",
    "        self.convs.append(tf.keras.layers.Conv2D(n_filter, kernel_size, padding='SAME'))\n",
    "        \n",
    "    def call(self, x):\n",
    "        y = x\n",
    "        for conv in self.convs:\n",
    "            y = conv(y)\n",
    "        return y\n",
    "\n",
    "class ResidualConvRegressor(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, filters, kernel_size, n_freq_residual, \n",
    "        conv_type=tf.keras.layers.Conv2D, activation=tf.nn.elu, \n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.n_freq_residual = n_freq_residual\n",
    "        self.conv_type = conv_type\n",
    "        self.convs = []\n",
    "        for n_filter in filters:\n",
    "            self.convs.append(\n",
    "                conv_type(\n",
    "                    n_filter, round_even(kernel_size), strides=2, \n",
    "                    activation=activation, padding='SAME', **kwargs)\n",
    "            )\n",
    "            for i in range(n_freq_residual):\n",
    "                self.convs.append(\n",
    "                    ResidualConv(n_filter, kernel_size, activation=activation, **kwargs)\n",
    "                )\n",
    "        self.convs.append(tf.keras.layers.Conv2D(n_filter, kernel_size, padding='SAME'))\n",
    "        \n",
    "    def call(self, x):\n",
    "        y = x\n",
    "        for conv in self.convs:\n",
    "            y = conv(y)\n",
    "        return y\n",
    "    \n",
    "class ConvVAE(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, dim_list, latent_dim, out_ch=1, kernel_size=3, **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.inference_net = self.create_regressor(\n",
    "            dim_list, kernel_size, conv_type=tf.keras.layers.Conv2D,\n",
    "            **kwargs)\n",
    "        self.dense_inference = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(latent_dim * 2),\n",
    "        ])\n",
    "\n",
    "        self.generative_net = self.create_regressor(\n",
    "            dim_list[::-1], kernel_size, conv_type=tf.keras.layers.Conv2DTranspose,\n",
    "            **kwargs)\n",
    "\n",
    "    def create_regressor(self, dim_list, kernel_size, **kwargs):\n",
    "        return ConvRegressor(dim_list, kernel_size=kernel_size, **kwargs)\n",
    "        \n",
    "    def call(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        return self.decode(z)\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        self.orig_latent = self.inference_net(x)\n",
    "        self.latent = self.dense_inference(self.orig_latent)\n",
    "        mean, logvar = tf.split(self.latent, num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        s = int(np.sqrt(z.shape[1]))\n",
    "        #print(self.latent.shape, s, z.shape)\n",
    "        z = tf.reshape(z, (tf.shape(z)[0], s, s, 1))\n",
    "        logits = self.generative_net(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "\n",
    "        return logits\n",
    "    \n",
    "class ResidualConvVAE(ConvVAE):\n",
    "    def __init__(\n",
    "        self, dim_list, latent_dim, n_freq_residual=4,\n",
    "        kernel_size=3, **kwargs\n",
    "    ):\n",
    "        self.n_freq_residual = n_freq_residual\n",
    "        super().__init__(dim_list, latent_dim, kernel_size, **kwargs)\n",
    "\n",
    "    def create_regressor(self, dim_list, kernel_size, **kwargs):\n",
    "        return ResidualConvRegressor(\n",
    "            dim_list, kernel_size=kernel_size,\n",
    "            n_freq_residual=self.n_freq_residual, **kwargs)\n",
    "        \n",
    "#net = ConvVAE([1, 16, 32], 64, kernel_size=3)\n",
    "net = ResidualConvVAE([1, 16, 32], 64, n_freq_residual=4, kernel_size=3)\n",
    "output = net(tf.random.uniform((4, 64, 64, 1)))\n",
    "net.summary()\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2020-05-29T15:00:35.736Z",
     "iopub.status.busy": "2020-05-29T15:00:35.733Z",
     "iopub.status.idle": "2020-05-29T15:00:36.370Z",
     "shell.execute_reply": "2020-05-29T15:00:36.375Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Load breast cancer dataset\n",
    "from sklearn.datasets import load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "import pandas as pd\n",
    "xs = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "ys = data.target\n",
    "\n",
    "mu_std = {}\n",
    "for col in xs.columns:\n",
    "    mu = xs[col].mean()\n",
    "    std = xs[col].std()\n",
    "    xs[col] = (xs[col] - mu) / std\n",
    "    mu_std[col] = (mu, std)\n",
    "\n",
    "train_indices, test_indices = train_test_split(range(len(xs)))\n",
    "train_xs = xs.iloc[train_indices]\n",
    "test_xs = xs.iloc[test_indices]\n",
    "\n",
    "TRAIN_BUF = 1000\n",
    "BATCH_SIZE = 32\n",
    "TEST_BUF = 1000\n",
    "n_input_dim = train_xs.shape[1]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_xs.astype(np.float32)).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_xs.astype(np.float32)).shuffle(TEST_BUF).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2020-05-29T15:01:16.805Z",
     "iopub.status.busy": "2020-05-29T15:01:16.802Z",
     "iopub.status.idle": "2020-05-29T15:01:16.862Z",
     "shell.execute_reply": "2020-05-29T15:01:16.866Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Load digits.\n",
    "from sklearn.datasets import load_wine, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits, labels = load_digits(return_X_y=True)\n",
    "digits = (digits / 16).astype(np.float32).reshape(-1, 8, 8, 1)\n",
    "\n",
    "import pandas as pd\n",
    "train_indices, test_indices = train_test_split(range(len(digits)))\n",
    "train_xs = digits[train_indices].reshape(-1, 8, 8, 1)\n",
    "test_xs = digits[test_indices]\n",
    "\n",
    "TRAIN_BUF = 1000\n",
    "BATCH_SIZE = 32\n",
    "TEST_BUF = 1000\n",
    "n_input_dim = train_xs.shape[1]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_xs).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_xs).shuffle(TEST_BUF).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac049865c83e48f8ac6c4354b6961c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([10, 10, 20], [30, 30, 30])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EpjC2hlVClEz",
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe6f832f2c5440e94d1ee1795bbc054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1b6f18b5324a6e89dd4502668f6caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### from IPython import display\n",
    "import IPython \n",
    "from collections import defaultdict \n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib widget\n",
    "#%matplotlib notebook\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "latent_dim = 4\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "#model = ResidualVAE([n_input_dim, 8, 4])\n",
    "model = ResidualConvVAE([1, 16,], latent_dim, kernel_size=3)\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3, beta_1=0.5, beta_2=0.99)\n",
    "\n",
    "def gaussian_kl_divergence(mean, ln_var, raxis=1):\n",
    "    var = tf.exp(ln_var)\n",
    "    mean_square = mean * mean\n",
    "    return tf.reduce_sum((mean_square + var - ln_var - 1) * 0.5, axis=raxis)\n",
    "\n",
    "\n",
    "#@tf.function\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    reconst_x = model.decode(z)\n",
    "\n",
    "    absolute_error = (reconst_x - x) ** 2\n",
    "    loss_reconst = tf.reduce_sum(absolute_error, axis=1)\n",
    "    loss_kld = gaussian_kl_divergence(mean, logvar)\n",
    "\n",
    "    return {\n",
    "        'loss': {\n",
    "            'Reconstruct': tf.reduce_mean(loss_reconst),\n",
    "            'KL-d': tf.reduce_mean(loss_kld) * 1e-3,\n",
    "        },\n",
    "        'raw': {\n",
    "            'AE': absolute_error, \n",
    "            'Original': x,\n",
    "            'Reconstruct': reconst_x,\n",
    "        }\n",
    "    }\n",
    "\n",
    "#@tf.function\n",
    "def compute_apply_gradients(model, x, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        losses = compute_loss(model, x)\n",
    "        loss = sum(losses['loss'].values())\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return losses\n",
    "\n",
    "#fig, axes = plt.subplots(3, 1, figsize=(5, 8))\n",
    "fig = plt.figure(figsize=(5, 12))\n",
    "grid_shape = (6, 3)\n",
    "loss_ax = plt.subplot2grid(shape=grid_shape, loc=(0, 0), colspan=grid_shape[1], fig=fig)\n",
    "elbo_ax = plt.subplot2grid(shape=grid_shape, loc=(1, 0), colspan=grid_shape[1], fig=fig)\n",
    "data_ax = np.zeros((4,3), dtype=np.object)\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        data_ax[i, j] = plt.subplot2grid(shape=grid_shape, loc=(2 + i, j), fig=fig)\n",
    "\n",
    "        \n",
    "plt.ion()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "loss_history = defaultdict(list)\n",
    "elbo_history = []\n",
    "with tf.device('/GPU:0'):\n",
    "    for epoch in trange(1, epochs + 1):\n",
    "        start_time = time.time()\n",
    "        for train_x in train_dataset:\n",
    "            data = compute_apply_gradients(model, train_x, optimizer)\n",
    "            for name, loss in data['loss'].items():\n",
    "                loss_history[name].append(loss.numpy())\n",
    "        end_time = time.time()\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            loss = tf.keras.metrics.Mean()\n",
    "            raw = None\n",
    "            for test_x in test_dataset:\n",
    "                losses = compute_loss(model, test_x)\n",
    "                if raw is None:\n",
    "                    raw = losses['raw']\n",
    "                loss(sum(losses['loss'].values()))\n",
    "            elbo = -loss.result()\n",
    "            elbo_history.append(elbo)\n",
    "            \n",
    "            loss_ax.clear()\n",
    "            for name, loss in loss_history.items():\n",
    "                loss_ax.plot(loss, label=name, alpha=0.5)\n",
    "            loss_ax.set_xlabel('epoch')\n",
    "            loss_ax.set_ylabel('Loss')\n",
    "            loss_ax.set_yscale('log')\n",
    "            loss_ax.legend()\n",
    "\n",
    "            elbo_ax.clear()\n",
    "            elbo_ax.plot(elbo_history)\n",
    "\n",
    "            original = np.squeeze(raw['Original'].numpy())\n",
    "            reconstruct = np.squeeze(raw['Reconstruct'].numpy())\n",
    "            absolute_error = np.squeeze(raw['AE'].numpy())\n",
    "            if np.any(np.isnan(absolute_error)):\n",
    "                tqdm.write('The output is nan.')\n",
    "            for i in range(4):\n",
    "                ax = data_ax[i, 0]\n",
    "                ax.clear()\n",
    "                ax.imshow(original[i], vmin=0.0, vmax=1.0)\n",
    "                \n",
    "                ax = data_ax[i, 1]\n",
    "                ax.clear()\n",
    "                ax.imshow(reconstruct[i], vmin=0.0, vmax=1.0)\n",
    "                \n",
    "                ax = data_ax[i, 2]\n",
    "                ax.clear()\n",
    "                ax.imshow(absolute_error[i], vmin=0.0, vmax=1.0)\n",
    "            fig.canvas.draw()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOErb6gQB7rgn9bp/Q28Jiv",
   "collapsed_sections": [],
   "name": "autoencoder_gbdt.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.23.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
